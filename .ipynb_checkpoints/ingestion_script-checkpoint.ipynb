{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a61f5df6-93de-446c-ba53-6798b39b3279",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "import pydoop.hdfs as hdfs\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "54c944c3-3a79-48a9-a830-150047377f43",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['group', 'group1', 'group2', 'group3', 'group3 - copy', 'group4']\n"
     ]
    }
   ],
   "source": [
    "dirs = os.listdir('/home/itversity/itversity-material/retail_pipeline/data')\n",
    "groups = [d for d in dirs if os.path.isdir(os.path.join('/home/itversity/itversity-material/retail_pipeline/data', d)) and d.startswith('group')]\n",
    "print(groups)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea4b3f40-a585-4cb9-97eb-dce24adde8c3",
   "metadata": {},
   "source": [
    "- Function to write ingested files into a text file to skip them on the next round"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "08151d1d-1e47-48eb-bc42-56a3ffe433d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def write_dirs_to_file(file_path, group):\n",
    "    with open(file_path, 'r') as file:\n",
    "            existing_content = file.read().splitlines()\n",
    "            \n",
    "    with open(file_path, 'a') as file:\n",
    "        if group not in existing_content:\n",
    "            file.write(f\"{group}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e42751f3-be19-4799-9ec2-480b0f943eea",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "group1\n"
     ]
    }
   ],
   "source": [
    "with open('/home/itversity/itversity-material/retail_pipeline/data/written_groups.txt', 'r') as file:\n",
    "    skip_dir = file.read().splitlines()\n",
    "    \n",
    "filtered_dir = [group for group in groups if group not in skip_dir]\n",
    "if filtered_dir:\n",
    "    files = os.listdir(f\"/home/itversity/itversity-material/retail_pipeline/data/{filtered_dir[0]}\")\n",
    "else:\n",
    "    print(\"No new directories to process.\")\n",
    "    \n",
    "print(filtered_dir[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14aad0ad-74eb-41e4-a13f-7aa51b49fa7d",
   "metadata": {
    "tags": []
   },
   "source": [
    " Function to rename the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ee161aca-a9a7-47a1-8044-49354633b067",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('branches_SS_raw_1_20240630_12', '.csv')\n",
      "Renamed /home/itversity/itversity-material/retail_pipeline/data/group1/branches_SS_raw_1_20240630_12.csv to /home/itversity/itversity-material/retail_pipeline/data/group1/branches_SS_raw_1_20240630__20240703_12.csv\n",
      "Uploaded /home/itversity/itversity-material/retail_pipeline/data/group1/branches_SS_raw_1_20240630__20240703_12.csv to /data/retail_bronze/20240703/12/branches_SS_raw_1_20240630__20240703_12.csv\n",
      "('sales_agents_SS_raw_1_20240630_12', '.csv')\n",
      "Renamed /home/itversity/itversity-material/retail_pipeline/data/group1/sales_agents_SS_raw_1_20240630_12.csv to /home/itversity/itversity-material/retail_pipeline/data/group1/sales_agents_SS_raw_1_20240630__20240703_12.csv\n",
      "Uploaded /home/itversity/itversity-material/retail_pipeline/data/group1/sales_agents_SS_raw_1_20240630__20240703_12.csv to /data/retail_bronze/20240703/12/sales_agents_SS_raw_1_20240630__20240703_12.csv\n",
      "('sales_transactions_SS_raw_1_20240630_12', '.csv')\n",
      "Renamed /home/itversity/itversity-material/retail_pipeline/data/group1/sales_transactions_SS_raw_1_20240630_12.csv to /home/itversity/itversity-material/retail_pipeline/data/group1/sales_transactions_SS_raw_1_20240630__20240703_12.csv\n",
      "Uploaded /home/itversity/itversity-material/retail_pipeline/data/group1/sales_transactions_SS_raw_1_20240630__20240703_12.csv to /data/retail_bronze/20240703/12/sales_transactions_SS_raw_1_20240630__20240703_12.csv\n"
     ]
    }
   ],
   "source": [
    "def rename_files_and_upload(local_directory, hdfs_directory):\n",
    "    # Rename files\n",
    "    for file_name in files:\n",
    "        old_file_path = os.path.join(local_directory, file_name)\n",
    "        \n",
    "        # Get the current date and hour\n",
    "        now = datetime.now()\n",
    "        date_str = now.strftime(\"%Y%m%d\")\n",
    "        hour_str = now.strftime(\"%H\")\n",
    "        \n",
    "        # Split the file name and extension\n",
    "        split_name= os.path.splitext(file_name)\n",
    "        print(split_name)\n",
    "        # Create the new file name with the extension at the end\n",
    "        new_file_name = f\"{split_name[0][:-2]}_{date_str}_{hour_str}{split_name[1]}\"\n",
    "        new_file_path = os.path.join(local_directory, new_file_name)\n",
    "        \n",
    "        # Rename the file\n",
    "        try:\n",
    "            os.rename(old_file_path, new_file_path)\n",
    "            print(f\"Renamed {old_file_path} to {new_file_path}\")\n",
    "        except FileNotFoundError:\n",
    "            print(\"no new files found\")\n",
    "        \n",
    "        # Upload the renamed file to HDFS\n",
    "        hdfs.mkdir(f\"/data/retail_bronze/{date_str}/{hour_str}\")\n",
    "        day_directory = os.path.join(hdfs_directory, date_str)\n",
    "        hour_directory = os.path.join(day_directory, hour_str)\n",
    "        hdfs_file_path = os.path.join(hour_directory, new_file_name)\n",
    "        hdfs.put(new_file_path, hdfs_file_path)\n",
    "        print(f\"Uploaded {new_file_path} to {hdfs_file_path}\")\n",
    "\n",
    "if filtered_dir:\n",
    "    rename_files_and_upload(f\"/home/itversity/itversity-material/retail_pipeline/data/{filtered_dir[0]}\", '/data/retail_bronze')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db3d53ce-08d8-4853-8c98-c62a95ab7a32",
   "metadata": {},
   "source": [
    "write the already ingested files to the log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6e0e8bb8-5b4e-4f5c-8203-f89e6239e151",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "write_dirs_to_file('/home/itversity/itversity-material/retail_pipeline/data/written_groups.txt', filtered_dir[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6d574ef1-26d6-47d2-a827-90b2f2254f92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3360026c-820e-4bfc-b7cf-3ea130055f58",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
